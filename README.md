
# IPTCaptioning

**IPTCaptioning** √© um script de an√°lise automatizada de imagens que integra um modelo de *image captioning* (legenda autom√°tica) ao sistema de investiga√ß√£o forense digital [IPED](https://github.com/sepinf-inc/IPED), utilizando o modelo [BLIP](https://huggingface.co/Salesforce/blip-image-captioning-base) da Salesforce.

O script gera automaticamente descri√ß√µes para imagens e, opcionalmente, traduz as legendas para outro idioma.

---

## üß† Funcionalidades

- Gera√ß√£o de legendas para imagens usando o modelo BLIP.
- Suporte a **captioning condicional**, com prompt personalizado.
- Tradu√ß√£o autom√°tica das legendas para diversos idiomas via `deep-translator`.
- Integra√ß√£o nativa com o processamento do IPED.
- Compat√≠vel com CPU e GPU (via CUDA).

---

## ‚öôÔ∏è Integra√ß√£o com o IPED

### üß© Pr√©-requisitos

- IPED instalado (vers√£o compat√≠vel com tasks em Python).
- Python 3.9+ instalado.
- Ambiente com `pip` e acesso √† internet para instala√ß√£o de depend√™ncias.
- Download local do modelo BLIP.

---

## üõ†Ô∏è Configura√ß√£o

Siga os passos abaixo para instalar o `IPTCaptioning.py` no seu IPED:

### 1. Editar o arquivo `IPEDConfig.txt`

Adicione a seguinte linha:

```ini
enableImageCaptioning=true
```

---

### 2. Editar o arquivo `IPED_ROOT/conf/TaskInstaller.xml`

Adicione a seguinte tag dentro da lista de tasks:

```xml
<task script="IPTCaptioning.py"></task>
```

---

### 3. Baixar o modelo BLIP localmente

1. Crie o diret√≥rio abaixo (se ainda n√£o existir):

```bash
IPED_ROOT/models/salesforce
```

2. Acesse: [https://huggingface.co/Salesforce/blip-image-captioning-base/tree/main](https://huggingface.co/Salesforce/blip-image-captioning-base/tree/main)

3. Baixe todos os arquivos listados (como `config.json`, `pytorch_model.bin`, `preprocessor_config.json`, etc.)

4. Salve-os dentro do diret√≥rio criado:

```
IPED_ROOT/models/salesforce/
```

---

### 4. Instalar as depend√™ncias Python

Instale os pacotes abaixo (de prefer√™ncia em um ambiente virtual):

```bash
pip install numpy>=1.17,<2.0.0
pip install accelerate
pip install pillow
pip install deep-translator
pip install transformers
pip install torch==2.1.0 torchvision torchaudio
```

---

### 5. Salvar o arquivo de configura√ß√£o `IPTCaptioningConfig.txt`

1. Baixe o arquivo `IPTCaptioningConfig.txt` (dispon√≠vel neste reposit√≥rio).
2. Salve-o no diret√≥rio:

```
IPED_ROOT/conf/
```

Voc√™ pode personalizar as seguintes propriedades:

```ini
targetlanguage=pt            # Idioma de tradu√ß√£o (ex: pt, en, es)
showLog=true                 # Habilita ou desabilita a exibi√ß√£o de logs
captionPrompt=uma foto de   # Prompt condicional (opcional - Deixe em branco se nao quiser usar)
maxLength=70                # Tamanho m√°ximo da legenda
```

---

### 6. Salvar o script `IPTCaptioning.py`

1. Baixe o arquivo `IPTCaptioning.py` (dispon√≠vel neste reposit√≥rio).
2. Salve-o no diret√≥rio:

```
IPED_ROOT/scripts/tasks/
```

---

## üöÄ Execu√ß√£o

Ap√≥s as configura√ß√µes, basta rodar o IPED normalmente. As imagens processadas receber√£o uma legenda autom√°tica como atributo extra (`ImageCaptioning`), que pode ser visualizado no m√≥dulo de an√°lise do IPED (IPED-SearchApp.exe).

---

## üìÑ Licen√ßa do Modelo BLIP

Este projeto utiliza o modelo [Salesforce/blip-image-captioning-base](https://huggingface.co/Salesforce/blip-image-captioning-base), licenciado sob a licen√ßa **BSD-3-Clause**. Consulte o aviso de licen√ßa no diret√≥rio `models/salesforce` para mais detalhes.

---

### üîß Bibliotecas utilizadas

- [deep-translator](https://github.com/nidhaloff/deep-translator) ‚Äî biblioteca para tradu√ß√£o autom√°tica entre idiomas. Licen√ßa MIT.
